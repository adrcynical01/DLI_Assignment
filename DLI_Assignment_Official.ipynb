{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrcynical01/DLI_Assignment/blob/main/DLI_Assignment_Official.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.0 Importing the Libraries"
      ],
      "metadata": {
        "id": "nePcRVKi3H-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "XPe9USld3MxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Loading Dataset from google drive"
      ],
      "metadata": {
        "id": "znomjuO75W93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1A Loading through CSV file"
      ],
      "metadata": {
        "id": "m8LWbSA05bcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "JsApvcZi5fgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1B Loading through Mounting Address"
      ],
      "metadata": {
        "id": "_DvlUmwm5iQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/phishing_dataset.csv')\n",
        "\n",
        "print(\"Number of total records:\", len(dataset))\n",
        "print()\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "tgRPTv9H5meY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.0 Preparing the Data"
      ],
      "metadata": {
        "id": "f2FMZGzk7zqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate input features (X) from the target label (y)\n",
        "# 'Result' is the column that contains the label: 1 = phishing, -1 = legitimate\n",
        "X = dataset.drop('Result', axis=1).values\n",
        "y = dataset['Result'].values"
      ],
      "metadata": {
        "id": "4AtR3Jfz719V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Split into training and test sets using stratified sampling to preserve class balance\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Convert labels from -1/1 to 0/1 for binary classification\n",
        "y_train = np.where(y_train == -1, 0, 1)\n",
        "y_test = np.where(y_test == -1, 0, 1)\n",
        "\n",
        "# Optional: Check class distribution to confirm balance\n",
        "print(\"Train set class distribution:\", dict(zip(*np.unique(y_train, return_counts=True))))\n",
        "print(\"Test set class distribution:\", dict(zip(*np.unique(y_test, return_counts=True))))"
      ],
      "metadata": {
        "id": "5Fjmfvmk73mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.0 Defining the Neural Network Model"
      ],
      "metadata": {
        "id": "BJNr8p8g86XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Neccessary Libraries for Neural Network\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "90e4A7BY88GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.0 Compiling and Training the Model"
      ],
      "metadata": {
        "id": "zn7lfAbl9F5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Rebuild the model with more capacity\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # More neurons\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary output\n",
        "\n",
        "# Print model architecture\n",
        "model.summary()\n",
        "\n",
        "# Compile the model using binary crossentropy for binary classification\n",
        "# 'adam' optimizer adjusts learning efficiently\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to prevent overfitting if val_loss stops improving\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Compute class weights from training labels\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}\n",
        "print(\"Class Weights:\", class_weight_dict)\n",
        "\n",
        "# Train the model with training data, using 20% for validation\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "Bapf3-yH9IoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.1 Baseline Comparison using Decision Tree"
      ],
      "metadata": {
        "id": "13QlFGqAGtqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "# Select 2 binary/categorical features (e.g., ShortURL and Symbol@)\n",
        "feature_names = ['ShortURL', 'Symbol@']\n",
        "X_vis = dataset[feature_names].values\n",
        "y_vis = dataset['Result'].values\n",
        "\n",
        "# Train a simple decision tree classifier\n",
        "dt_vis = DecisionTreeClassifier(random_state=42)\n",
        "dt_vis.fit(X_vis, y_vis)\n",
        "\n",
        "# Create a discrete meshgrid covering -1 to 1 for both features\n",
        "xx, yy = np.meshgrid(np.arange(-1, 2, 1), np.arange(-1, 2, 1))\n",
        "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "Z = dt_vis.predict(grid_points).reshape(xx.shape)\n",
        "\n",
        "# Plot decision surface using discrete levels\n",
        "plt.figure(figsize=(6, 6))\n",
        "cmap_bg = ListedColormap(['#FFAAAA', '#AAFFAA'])  # background\n",
        "plt.contourf(xx, yy, Z, cmap=cmap_bg, alpha=0.6)\n",
        "\n",
        "# Overlay actual points\n",
        "for class_value in np.unique(y_vis):\n",
        "    plt.scatter(X_vis[y_vis == class_value, 0],\n",
        "                X_vis[y_vis == class_value, 1],\n",
        "                label=f\"Class {class_value}\",\n",
        "                edgecolor='k')\n",
        "\n",
        "plt.title(\" Decision Tree (ShortURL vs Symbol@)\")\n",
        "plt.xlabel('ShortURL')\n",
        "plt.ylabel('Symbol@')\n",
        "plt.xticks([-1, 0, 1])\n",
        "plt.yticks([-1, 0, 1])\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0EXwBcgyGyjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Logistic Regression comparison with Neural Network"
      ],
      "metadata": {
        "id": "xF2s98qlH6nP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
        ")\n",
        "\n",
        "# 1) Train Logistic Regression (with scaling)\n",
        "lr = make_pipeline(\n",
        "    StandardScaler(),  # helps LR converge / perform better\n",
        "    LogisticRegression(max_iter=500, class_weight='balanced', solver='lbfgs')\n",
        ")\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# 2) LR predictions & probabilities\n",
        "y_lr_prob = lr.predict_proba(X_test)[:, 1]\n",
        "y_lr_pred = (y_lr_prob >= 0.5).astype(int)\n",
        "\n",
        "# 3) NN predictions (recompute if not already available)\n",
        "try:\n",
        "    y_nn_prob = y_prob.ravel()\n",
        "    y_nn_pred = y_pred.ravel().astype(int)\n",
        "except NameError:\n",
        "    y_nn_prob = model.predict(X_test, verbose=0).ravel()\n",
        "    y_nn_pred = (y_nn_prob >= 0.5).astype(int)\n",
        "\n",
        "# 4) Metrics\n",
        "def metrics(y_true, y_hat, y_scores):\n",
        "    return {\n",
        "        \"Accuracy\": accuracy_score(y_true, y_hat),\n",
        "        \"Precision\": precision_score(y_true, y_hat),\n",
        "        \"Recall\": recall_score(y_true, y_hat),\n",
        "        \"F1\": f1_score(y_true, y_hat),\n",
        "        \"ROC-AUC\": roc_auc_score(y_true, y_scores)\n",
        "    }\n",
        "\n",
        "lr_metrics = metrics(y_test, y_lr_pred, y_lr_prob)\n",
        "nn_metrics = metrics(y_test, y_nn_pred, y_nn_prob)\n",
        "\n",
        "# 5) Print classification report for LR (optional)\n",
        "print(\"=== Logistic Regression: classification report ===\")\n",
        "print(classification_report(y_test, y_lr_pred, digits=3))\n",
        "\n",
        "# 6) Confusion matrices (optional visuals)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10,4))\n",
        "sns.heatmap(confusion_matrix(y_test, y_lr_pred), annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
        "axes[0].set_title(\"LR Confusion Matrix\"); axes[0].set_xlabel(\"Predicted\"); axes[0].set_ylabel(\"Actual\")\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test, y_nn_pred), annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
        "axes[1].set_title(\"NN Confusion Matrix\"); axes[1].set_xlabel(\"Predicted\"); axes[1].set_ylabel(\"Actual\")\n",
        "plt.tight_layout(); plt.show()\n",
        "\n",
        "# 7) Combined ROC (LR vs NN)\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_lr_prob)\n",
        "fpr_nn, tpr_nn, _ = roc_curve(y_test, y_nn_prob)\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "plt.plot(fpr_lr, tpr_lr, label=f\"LR ROC (AUC = {lr_metrics['ROC-AUC']:.3f})\")\n",
        "plt.plot(fpr_nn, tpr_nn, label=f\"NN ROC (AUC = {nn_metrics['ROC-AUC']:.3f})\")\n",
        "plt.plot([0,1],[0,1],'k--', lw=1)\n",
        "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curves: Logistic Regression vs Neural Net\")\n",
        "plt.legend(); plt.grid(True, alpha=0.3); plt.tight_layout(); plt.show()\n",
        "\n",
        "# 8) Side-by-side metrics table\n",
        "comparison_df = pd.DataFrame([\n",
        "    {\"Model\": \"Logistic Regression\", **lr_metrics},\n",
        "    {\"Model\": \"Neural Net (Keras)\", **nn_metrics},\n",
        "]).set_index(\"Model\")\n",
        "\n",
        "display(comparison_df.style.format(\"{:.3f}\"))\n",
        "\n",
        "# (Optional) Save to results/\n",
        "comparison_df.to_csv(\"results/baseline_vs_nn_metrics.csv\", index=True)\n",
        "print(\"Saved: results/baseline_vs_nn_metrics.csv\")\n"
      ],
      "metadata": {
        "id": "em64kjhYG3Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.0 Model Evaluation"
      ],
      "metadata": {
        "id": "ao8tD-jV_2G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy: %.2f%%\" % (accuracy * 100))\n"
      ],
      "metadata": {
        "id": "VF9L8tVG_6Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.0 Additional Metrics and Evaluation"
      ],
      "metadata": {
        "id": "aatIfh36B6wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Predict probabilities and convert to binary predictions (threshold = 0.5)\n",
        "y_prob = model.predict(X_test)\n",
        "y_pred = (y_prob > 0.5).astype(int)\n",
        "\n",
        "# Use y_test and y_pred directly (already in 0/1 format)\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_score(y_test, y_prob):.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Random baseline\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Training and Validation Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Model Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Training and Validation Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VpkaU-DaB-yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final F1-score verdict\n",
        "final_f1 = f1_score(y_test, y_pred)\n",
        "print(f\"\\nâœ… Verdict: Achieved F1 = {final_f1:.2f}, target {'met âœ…' if final_f1 >= 0.90 else 'not met âŒ'}\")"
      ],
      "metadata": {
        "id": "4nZUi9tYDAx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "AHz63JbjDMwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.0 Saving and Loading the Model"
      ],
      "metadata": {
        "id": "obwWHjBRDv8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to disk\n",
        "model.save('phishing_model.keras')\n",
        "\n",
        "# Later, load the model to reuse without retraining\n",
        "from keras.models import load_model\n",
        "loaded_model = load_model('phishing_model.keras')"
      ],
      "metadata": {
        "id": "tQ8tzfXnD1AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.0 Making Prediction"
      ],
      "metadata": {
        "id": "nlzjoiMkExvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# List of all 30 feature names (from your dataset)\n",
        "feature_names = [\n",
        "    'UsingIP', 'LongURL', 'ShortURL', 'Symbol@', 'Redirecting//', 'PrefixSuffix-', 'SubDomains',\n",
        "    'HTTPS', 'DomainRegLen', 'Favicon', 'NonStdPort', 'HTTPSDomainURL', 'RequestURL', 'AnchorURL',\n",
        "    'LinksInScriptTags', 'ServerFormHandler', 'InfoEmail', 'AbnormalURL', 'WebsiteForwarding',\n",
        "    'StatusBarCust', 'DisableRightClick', 'UsingPopupWindow', 'IframeRedirection', 'AgeofDomain',\n",
        "    'DNSRecording', 'WebsiteTraffic', 'PageRank', 'GoogleIndex', 'LinksPointingToPage', 'StatsReport'\n",
        "]\n",
        "\n",
        "# Prompt the user for each feature value\n",
        "input_values = []\n",
        "print(\"To test the model manually, enter values for each of the 30 features (-1, 0, or 1) below. The model will predict if the website is phishing or legitimate11:\")\n",
        "for name in feature_names:\n",
        "    while True:\n",
        "        try:\n",
        "            val = int(input(f\"{name}: \"))\n",
        "            if val in [-1, 0, 1]:\n",
        "                input_values.append(val)\n",
        "                break\n",
        "            else:\n",
        "                print(\"Enter only -1, 0, or 1.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter an integer.\")\n",
        "\n",
        "# Convert input to array for prediction\n",
        "sample_input = np.array([input_values])\n",
        "\n",
        "# Predict using the loaded model\n",
        "prediction = loaded_model.predict(sample_input)\n",
        "predicted_class = np.where(prediction > 0.5, 1, -1)[0][0]\n",
        "\n",
        "# Print result\n",
        "if predicted_class == 1:\n",
        "    print(\"ðŸ”’ This website is predicted to be PHISHING.\")\n",
        "else:\n",
        "    print(\"âœ… This website is predicted to be LEGITIMATE.\")"
      ],
      "metadata": {
        "id": "z9g6MPNOE13M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}