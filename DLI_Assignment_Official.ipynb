{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrcynical01/DLI_Assignment/blob/main/DLI_Assignment_Official.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.0 Importing the Libraries"
      ],
      "metadata": {
        "id": "nePcRVKi3H-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "XPe9USld3MxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Loading Dataset from google drive"
      ],
      "metadata": {
        "id": "znomjuO75W93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1A Loading through CSV file"
      ],
      "metadata": {
        "id": "m8LWbSA05bcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "JsApvcZi5fgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1B Loading through Mounting Address"
      ],
      "metadata": {
        "id": "_DvlUmwm5iQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/phishing_dataset.csv')\n",
        "\n",
        "print(\"Number of total records:\", len(dataset))\n",
        "print()\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "tgRPTv9H5meY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.0 Preparing the Data"
      ],
      "metadata": {
        "id": "f2FMZGzk7zqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate input features (X) from the target label (y)\n",
        "# 'Result' is the column that contains the label: 1 = phishing, -1 = legitimate\n",
        "X = dataset.drop('Result', axis=1).values\n",
        "y = dataset['Result'].values"
      ],
      "metadata": {
        "id": "4AtR3Jfz719V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Split into training and test sets using stratified sampling to preserve class balance\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Convert labels from -1/1 to 0/1 for binary classification\n",
        "y_train = np.where(y_train == -1, 0, 1)\n",
        "y_test = np.where(y_test == -1, 0, 1)\n",
        "\n",
        "# Optional: Check class distribution to confirm balance\n",
        "print(\"Train set class distribution:\", dict(zip(*np.unique(y_train, return_counts=True))))\n",
        "print(\"Test set class distribution:\", dict(zip(*np.unique(y_test, return_counts=True))))"
      ],
      "metadata": {
        "id": "5Fjmfvmk73mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.0 Defining the Neural Network Model"
      ],
      "metadata": {
        "id": "BJNr8p8g86XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Neccessary Libraries for Neural Network\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "90e4A7BY88GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.0 Compiling and Training the Model"
      ],
      "metadata": {
        "id": "zn7lfAbl9F5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Rebuild the model with more capacity\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # More neurons\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary output\n",
        "\n",
        "# Print model architecture\n",
        "model.summary()\n",
        "\n",
        "# Compile the model using binary crossentropy for binary classification\n",
        "# 'adam' optimizer adjusts learning efficiently\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to prevent overfitting if val_loss stops improving\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Compute class weights from training labels\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}\n",
        "print(\"Class Weights:\", class_weight_dict)\n",
        "\n",
        "# Train the model with training data, using 20% for validation\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "Bapf3-yH9IoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.0 Model Evaluation"
      ],
      "metadata": {
        "id": "ao8tD-jV_2G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy: %.2f%%\" % (accuracy * 100))\n"
      ],
      "metadata": {
        "id": "VF9L8tVG_6Jd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}