{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adrcynical01/DLI_Assignment/blob/main/DLI_Assignment_Official.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.0 Importing the Libraries"
      ],
      "metadata": {
        "id": "nePcRVKi3H-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "XPe9USld3MxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1 Loading Dataset from google drive"
      ],
      "metadata": {
        "id": "znomjuO75W93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1A Loading through CSV file"
      ],
      "metadata": {
        "id": "m8LWbSA05bcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "JsApvcZi5fgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.1B Loading through Mounting Address"
      ],
      "metadata": {
        "id": "_DvlUmwm5iQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Importing the dataset\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/phishing_dataset.csv')\n",
        "\n",
        "print(\"Number of total records:\", len(dataset))\n",
        "print()\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "tgRPTv9H5meY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.0 Preparing the Data"
      ],
      "metadata": {
        "id": "f2FMZGzk7zqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate input features (X) from the target label (y)\n",
        "# 'Result' is the column that contains the label: 1 = phishing, -1 = legitimate\n",
        "X = dataset.drop('Result', axis=1).values\n",
        "y = dataset['Result'].values"
      ],
      "metadata": {
        "id": "4AtR3Jfz719V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Split into training and test sets using stratified sampling to preserve class balance\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Convert labels from -1/1 to 0/1 for binary classification\n",
        "y_train = np.where(y_train == -1, 0, 1)\n",
        "y_test = np.where(y_test == -1, 0, 1)\n",
        "\n",
        "# Optional: Check class distribution to confirm balance\n",
        "print(\"Train set class distribution:\", dict(zip(*np.unique(y_train, return_counts=True))))\n",
        "print(\"Test set class distribution:\", dict(zip(*np.unique(y_test, return_counts=True))))"
      ],
      "metadata": {
        "id": "5Fjmfvmk73mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.0 Defining the Neural Network Model"
      ],
      "metadata": {
        "id": "BJNr8p8g86XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the Neccessary Libraries for Neural Network\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "90e4A7BY88GB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.0 Compiling and Training the Model"
      ],
      "metadata": {
        "id": "zn7lfAbl9F5n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import class_weight\n",
        "import numpy as np\n",
        "\n",
        "# Rebuild the model with more capacity\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # More neurons\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Binary output\n",
        "\n",
        "# Print model architecture\n",
        "model.summary()\n",
        "\n",
        "# Compile the model using binary crossentropy for binary classification\n",
        "# 'adam' optimizer adjusts learning efficiently\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Early stopping to prevent overfitting if val_loss stops improving\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Compute class weights from training labels\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(y_train),\n",
        "    y=y_train\n",
        ")\n",
        "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}\n",
        "print(\"Class Weights:\", class_weight_dict)\n",
        "\n",
        "# Train the model with training data, using 20% for validation\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop],\n",
        "    class_weight=class_weight_dict,\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "Bapf3-yH9IoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.0 Model Evaluation"
      ],
      "metadata": {
        "id": "ao8tD-jV_2G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy: %.2f%%\" % (accuracy * 100))\n"
      ],
      "metadata": {
        "id": "VF9L8tVG_6Jd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.0 Additional Metrics and Evaluation"
      ],
      "metadata": {
        "id": "aatIfh36B6wD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Predict probabilities and convert to binary predictions (threshold = 0.5)\n",
        "y_prob = model.predict(X_test)\n",
        "y_pred = (y_prob > 0.5).astype(int)\n",
        "\n",
        "# Use y_test and y_pred directly (already in 0/1 format)\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "plt.plot(fpr, tpr, label=f'ROC curve (AUC = {roc_auc_score(y_test, y_prob):.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Random baseline\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Training and Validation Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.title('Model Accuracy Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot Training and Validation Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VpkaU-DaB-yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final F1-score verdict\n",
        "final_f1 = f1_score(y_test, y_pred)\n",
        "print(f\"\\n✅ Verdict: Achieved F1 = {final_f1:.2f}, target {'met ✅' if final_f1 >= 0.90 else 'not met ❌'}\")"
      ],
      "metadata": {
        "id": "4nZUi9tYDAx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "AHz63JbjDMwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.0 Saving and Loading the Model"
      ],
      "metadata": {
        "id": "obwWHjBRDv8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model to disk\n",
        "model.save('phishing_model.keras')\n",
        "\n",
        "# Later, load the model to reuse without retraining\n",
        "from keras.models import load_model\n",
        "loaded_model = load_model('phishing_model.keras')"
      ],
      "metadata": {
        "id": "tQ8tzfXnD1AU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.0 Making Prediction"
      ],
      "metadata": {
        "id": "nlzjoiMkExvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# List of all 30 feature names (from your dataset)\n",
        "feature_names = [\n",
        "    'UsingIP', 'LongURL', 'ShortURL', 'Symbol@', 'Redirecting//', 'PrefixSuffix-', 'SubDomains',\n",
        "    'HTTPS', 'DomainRegLen', 'Favicon', 'NonStdPort', 'HTTPSDomainURL', 'RequestURL', 'AnchorURL',\n",
        "    'LinksInScriptTags', 'ServerFormHandler', 'InfoEmail', 'AbnormalURL', 'WebsiteForwarding',\n",
        "    'StatusBarCust', 'DisableRightClick', 'UsingPopupWindow', 'IframeRedirection', 'AgeofDomain',\n",
        "    'DNSRecording', 'WebsiteTraffic', 'PageRank', 'GoogleIndex', 'LinksPointingToPage', 'StatsReport'\n",
        "]\n",
        "\n",
        "# Prompt the user for each feature value\n",
        "input_values = []\n",
        "print(\"To test the model manually, enter values for each of the 30 features (-1, 0, or 1) below. The model will predict if the website is phishing or legitimate11:\")\n",
        "for name in feature_names:\n",
        "    while True:\n",
        "        try:\n",
        "            val = int(input(f\"{name}: \"))\n",
        "            if val in [-1, 0, 1]:\n",
        "                input_values.append(val)\n",
        "                break\n",
        "            else:\n",
        "                print(\"Enter only -1, 0, or 1.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter an integer.\")\n",
        "\n",
        "# Convert input to array for prediction\n",
        "sample_input = np.array([input_values])\n",
        "\n",
        "# Predict using the loaded model\n",
        "prediction = loaded_model.predict(sample_input)\n",
        "predicted_class = np.where(prediction > 0.5, 1, -1)[0][0]\n",
        "\n",
        "# Print result\n",
        "if predicted_class == 1:\n",
        "    print(\"🔒 This website is predicted to be PHISHING.\")\n",
        "else:\n",
        "    print(\"✅ This website is predicted to be LEGITIMATE.\")"
      ],
      "metadata": {
        "id": "z9g6MPNOE13M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}